# Descriptive-Semantic-Image-Translation-with-FlexIT

Using GANs to generate photorealistic images has become rather commonplace in computer vision. However, our control over diversity and features 
of images is limited. Most recent research in image editing and semantic image translation improves architecture, replacing GANs with VQGAN autoencoders. 
Given text about original features and target features, a newly proposed method, FlexIT, can perform transformations with minimal changes 
and close resemblance to the input image. We will extend FlexIT to deal with more complicated textual descriptions it is not previously 
capable of handling, such as transforming objects in the input image that are not the main object. More descriptive texts will be supported 
to illustrate the input and target objects.
